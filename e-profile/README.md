# ECMWF Software with Documentation (SD) Deliverable

**Project / Activity Name:** E-PROFILE Wind Profilers' Data Processing System
**Version:** 1.0.0
**Date:** 2025-11-24
**Author(s):** Faezeh Karimian Saracks, Fabio Madonna, Emanuele Tramutola

---

## 1. Purpose
This document includes workflow explanations, expanded scientific background, block-diagram visualizations, and technical commentary on each component
of the R scripts used to retrieve and process the E-PROFILE wind profilers' data and obtained the time-aggregated version of the datasets, specifically designed for the 
Copernicus Data Store.

The processing workflow performs: metadata extraction 
- data access and download (including handling of certificates to access the data)
- raw data extraction and filtering 
- cleaning 
- computation of wind metrics 
- multiple aggregation levels (hourly/daily/monthly/yearly)
- NetCDF export per station and height level.

EUMETNET's E-PROFILE programme (https://e-profile.eu/) is specifically dedicated to the collection, processing, and dissemination of wind profiler data. 
This program aims to create a continuous and reliable observation network of wind profiles, which is essential for weather forecasting, climate modeling, 
and emergency management. The main goal is to improve the overall usability of wind profiler data for operational meteorology and 
to provide support and expertise to both profiler operators and end users. 

---

## 2. Audience
This guide is intended for: 
• Atmospheric scientists 
• Data engineers working with large observational datasets 
• Research groups performing climate
reanalysis 
• Renewable energy specialists analysing wind behaviour.

---

## 3. Software Repository
**Repository URL:** [https://github.com/fabiomadonna/C3S2_311_bis/e-profile]

**Repository Structure:**

E-PROFILE/
├── README.md
├── eprofile.sh # Bash script to download CEDA WINPRO datasets
├── e-profile.R # R script for metadata extraction, cleaning, aggregation, NetCDF creation
├── Data_eprofile/ # Directory for raw and downloaded WINPRO CSV files
├── metadata/
│ └── FinalCheck_datevalid_distinct_merged_metadata.xlsx # Station metadata for processing
├── logs/ # Processing and filtering logs
├── output/ # Aggregated CSVs and NetCDF files
├── scripts/ # Optional additional helper scripts
└── external/ # External repositories (e.g., online_ca_client) or certificates

This repository contains the scripts and input files needed to download, process, and aggregate E-PROFILE wind profiler data. The structure is as follows:

- `eprofile.sh`               - Bash script to download CEDA WINPRO datasets and manage certificates
- `e-profile.R`               - R script for metadata extraction, data cleaning, filtering, aggregation, and NetCDF creation
- `Data_eprofile/`            - Directory for raw and downloaded CSV data
- `metadata/`                 - Station metadata files (`FinalCheck_datevalid_distinct_merged_metadata.xlsx`)
- `logs/`                     - Processing and filtering log files generated by the R script
- `output/`                   - Aggregated CSV and NetCDF outputs
- `README.md`                 - This file describing the repository
- `external/`                 - External repositories or tools (e.g., `online_ca_client`) and certificates if needed


### Notes

- **Data_eprofile/**: contains all CSV input files to be processed by `e-profile.R`. These are typically downloaded using `eprofile.sh`.  
- **metadata/FinalCheck_datevalid_distinct_merged_metadata.xlsx**: provides station metadata such as location, height, and instrument details.  
- **logs/**: stores filtering and QC logs generated during processing.  
- **output/**: stores processed CSV and NetCDF outputs.  
- **external/**: any external repository clones (e.g., `online_ca_client`) or certificate files.  
- **scripts/**: additional R or Bash helper scripts if needed.  


**License:** CC-BY-4.0

---

## 4. Technical Specifications

**Programming Language:**  
- R 4.3+ (tested with R 4.3.1)  
- Bash 5+ (for `eprofile.sh`)

**Package Management / Environment:**  
- R packages: `readr`, `dplyr`, `data.table`, `lubridate`, `foreach`, `doParallel`, `fasttime`, `readxl`, `magrittr`, `ncdf4`, `writexl`, `zoo`, `parallel`  
- Bash dependencies: `git`, `wget`, `curl`  

**Supported Operating Systems:**  
- Linux (tested on Ubuntu 20.04)  
- macOS  
- Windows (via R for Windows and Git Bash / WSL for Bash scripts)  

**System Requirements:**  
- **CPU:** Multi-core processor recommended for parallel processing  
- **RAM:** 8 GB minimum recommended (depends on data size)  
- **Storage:** Depends on the volume of WINPRO data being downloaded (tens of GB possible)  
- **Network:** Internet connection required for `eprofile.sh` to download datasets from CEDA  

**Notes:**  
- All processing is done locally; no external database is required.  
- NetCDF outputs comply with CF-1.8 conventions.  
---

## 5. Installation Instructions

### Prerequisites

Before running the scripts, ensure the following are installed on your system:

**1. R Environment:**  
- R 4.3+  
- R packages: `readr`, `dplyr`, `data.table`, `lubridate`, `foreach`, `doParallel`, `fasttime`, `readxl`, `magrittr`, `ncdf4`, `writexl`, `zoo`, `parallel`  
- Packages can be installed from CRAN using the `install.packages()` function.

**2. Bash Environment:**  
- Bash 5+ (comes pre-installed on most Linux/macOS systems; Windows users can use Git Bash or WSL)  
- Utilities: `git`, `wget`, `curl`

**3. Internet Connection:**  
- Required to download WINPRO data via `eprofile.sh` from the CEDA repository.

**4. File Permissions:**  
- Ensure read/write permissions for directories:  
  - `Data_eprofile/` (input CSVs)  
  - `metadata/` (station metadata)  
  - `logs/` (processing logs)  
  - `output/` (aggregated CSV and NetCDF files)  

**Optional:**  
- Enough disk space for storing downloaded data and NetCDF outputs (tens of GB depending on the dataset size).  

___

### Installation Steps

Follow these steps to set up the environment and prepare the repository for processing:

**6. Clone the repository**

git clone https://github.com/yourusername/E-PROFILE.git

cd E-PROFILE

Prepare directories:
Ensure the following directories exist (the scripts will create them if missing):
mkdir -p Data_eprofile logs output metadata external

Install R packages:
Open R or RStudio and run:
required_packages <- c(
  "readr","dplyr","parallel","lubridate","foreach","doParallel",
  "fasttime","data.table","readxl","magrittr","ncdf4","writexl","zoo","parallel"
)
for (pkg in required_packages) {
  if (!require(pkg, character.only = TRUE)) {
    install.packages(pkg, dependencies = TRUE)
  }
}

Download WINPRO data with Bash script:
bash eprofile.sh
This will populate Data_eprofile/ with raw CSV files.
Certificates or external tools may be stored in external/.

Process data with R script:
source("e-profile.R")
Outputs (aggregated CSVs and NetCDF) will be saved in output/.

Logs will be saved in logs/.

Verify outputs:
Check output/ for generated CSV and NetCDF files. Logs in logs/ can be used to verify filtering and QC steps.

---

**7. WORKFLOW SCHEME (TEXT VERSION) AND DETAILED EXPLANATION OF MAIN SCRIPT SECTIONS**

RAW CSV FILES
¯ Metadata extraction (parallel)
¯ Data extraction: read, parse, filter blocks, unify
¯ Filtering step (implausible values, QC)
¯ Compute wind variables:
- wind speed
- wind direction
- wind power density
- turbulence intensity
- wind stress
¯ Aggregation:
® hourly
® daily (24-hour completeness check)
® monthly
® yearly
¯ Normalize time fields
¯ NetCDF export (station × height × period)
¯ Logs saved

7.1 Package loading
The script automatically installs and loads all required packages, ensuring portability.

7.2 Metadata extraction
Each CSV may contain one or more header blocks. The system reads them in parallel and
produces a metadata summary table grouped by station.

7.3 File processing
Each file is scanned to identify “data” blocks. Within each block:
- station and date_valid fields are extracted
- the block is parsed via data.table::fread
- variables X1, X4, X6, X7 are retained
- X4 is filtered for quality control
- logs count retained vs removed observations
  
7.4 Parallel extraction
Files are split into batches and computed with foreach/doParallel.
A global filtered dataset is produced and sorted.

7.5 Cleaning and physical variable computation
Wind speed = sqrt(u² + v²)
Wind direction = atan2(u, v)
Wind power density = ½ · r · U³
Turbine flags (cut-in, cut-out limits) are added.

7.6 Filtering steps
The script logs the impact of each filtering step at each height and station.

7.7 Aggregation workflow
– Hourly: statistical summaries including SD, turbulence intensity, wind run
– Daily: requires 24 hourly values
– Monthly: averages and extrema on daily values
– Yearly: averages and extrema on monthly values

7.8 NetCDF export
For each period (hourly/daily/monthly/yearly) and station:
- Long-format conversion
- Creation of NetCDF variables (values, timestamps, heights)
- Addition of metadata and CF-compliant attributes
  
7.9 ADDITIONAL RECOMMENDATIONS
• Keep metadata Excel file updated to avoid missing attributes in NetCDF.
• Prefer HPC clusters for >10 GB datasets.
• Ensure date formats are consistent.

---
## 8. Automatic Tests
---

## 9. Known Limitations

### Current Limitations

9.1 **Database Dependency**
    - None currently.

9.2 **Memory Usage**
   - Description: Parallel processing of large NetCDF files can consume significant RAM.
   - Workaround: Adjust the number of parallel workers if memory is constrained.

### Known Issues

See the issue tracker for a complete list of known bugs.

---

## 10. Documentation Summary

### Available Documentation

- **README.md** - Quick start and overview.
- **SoftwareUserGuide.md** - This document.

### Code Documentation

- Docstrings are provided for all major classes and functions (e.g., `GRUANProcessor`, `StationManager`).

---

## 11. Support and Contact

### Reporting Issues

To report bugs, please contact the development team or open an issue in the repository.

### Contributing

Contributions are welcome. Please ensure tests pass before submitting changes.

**Maintainer(s):**

- Fabio Madonna

---

## 12. Deliverable Compliance

- [x] Software placed in public repository
- [x] Complete source code included
- [x] Documentation included in repository
- [x] Installation instructions provided
- [x] Installation does not require administrator privileges
- [x] Automatic tests included and verified
- [x] Snapshot of test output provided
- [x] License specified
- [x] Software includes version number/release tag
- [x] Code follows ECMWF coding standards (if applicable)
- [x] README.md with quick start instructions
- [x] Example datasets or data access instructions provided
- [x] Citation information provided (if applicable)
- [x] Technical specifications documented

---

**Document Version:** 1.0.0
**Date:** 2025-11-24

